python trash


tags = [tagger.tag(nltk.word_tokenize(sentence)) for sentence in sentences]
tokens=open("tokens.txt", "a")
tagss=open("tags.txt", "a")
for sentence in tags:
	for tag in sentence:
		tokens.write(tag[0].encode('utf-8') + "\n")
		tagss.write(tag[1].encode('utf-8') + "\n")

tokens.close()
tagss.close()
